{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be959207-8334-4587-8467-1562baae824a",
   "metadata": {},
   "source": [
    "# Spark and mongodb connector setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1477d8fa-17ac-4f6e-bc73-2d272539fdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of libraries\n",
    "from pyspark import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Function to initialize Pyspark wiht MongoDB connector\n",
    "def init_spark():\n",
    "    mongo_conn = f\"mongodb://mongodb:27017/\"\n",
    "    db = \"CS4010\"\n",
    "    coll = \"accidents\"\n",
    "    conf = SparkConf()\n",
    "\n",
    "    # Download mongo-spark-connector and its dependencies.\n",
    "    conf.set(\"spark.jars.packages\",\n",
    "             \"org.mongodb.spark:mongo-spark-connector:10.0.2\")\n",
    "\n",
    "    # Set up read connection :\n",
    "    conf.set(\"spark.mongodb.read.connection.uri\", mongo_conn)\n",
    "    conf.set(\"spark.mongodb.read.database\", db)\n",
    "    conf.set(\"spark.mongodb.read.collection\", coll)\n",
    "\n",
    "    # Set up write connection\n",
    "    conf.set(\"spark.mongodb.write.connection.uri\", mongo_conn)\n",
    "    conf.set(\"spark.mongodb.write.database\", db)\n",
    "    conf.set(\"spark.mongodb.write.collection\", coll)\n",
    "\n",
    "    SparkContext(conf=conf)\n",
    "\n",
    "    return SparkSession \\\n",
    "        .builder \\\n",
    "        .appName('myApp') \\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Create the spark session    \n",
    "spark = init_spark()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e0f92f-3bb9-4371-8caa-04344d474b0e",
   "metadata": {},
   "source": [
    "# Transform and insert accident data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4136212c-543f-49a5-a1e9-047ccf6af625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----------+-----------------+---------------+--------------------+-----------+----------+---------------+----------------+------------------+------------------+\n",
      "|      road_reference|          timestamp|speed_limit|          weather|road_conditions| lighting_conditions|road_lights|road_width|      road_type|       lane_type|               lon|               lat|\n",
      "+--------------------+-------------------+-----------+-----------------+---------------+--------------------+-----------+----------+---------------+----------------+------------------+------------------+\n",
      "|RV162 S1D1 m2472 ...|2020-08-17 12:17:00|         50|God sikt, opphold|  Tørr, bar veg|             Dagslys|         Ja|      15,4|Vanlig veg/gate|          Ukjent| 10.75370462750887|   59.912271465439|\n",
      "|     RV162 S1D1 m572|2020-08-07 06:51:00|         50|God sikt, opphold|  Tørr, bar veg|             Dagslys|         Ja|      null|Vanlig veg/gate|Vanlig kjørefelt|10.760100208019608|  59.9037207739809|\n",
      "|RV162 S1D1 m2472 ...|2020-01-14 21:50:00|         50| God sikt, nedbør|   Våt, bar veg|Mørkt med vegbely...|         Ja|      15,4|Vanlig veg/gate|Vanlig kjørefelt|10.754181391475317| 59.91215798596863|\n",
      "|    RV162 S1D1 m1355|2020-05-29 14:28:00|         50|God sikt, opphold|  Tørr, bar veg|             Dagslys|     Ukjent|      null|Vanlig veg/gate|Vanlig kjørefelt|10.759686077233697|59.903445162193236|\n",
      "|    RV162 S1D1 m4196|2020-02-07 10:55:00|         50|God sikt, opphold|   Våt, bar veg|             Dagslys|         Ja|      10,6|Vanlig veg/gate|Vanlig kjørefelt|10.731668793132876| 59.91495970650145|\n",
      "|    RV162 S1D1 m3878|2020-08-08 23:10:00|         50|           Ukjent|         Ukjent| Tussmørke, skumring|     Ukjent|      16,5|Vanlig veg/gate|Vanlig kjørefelt|10.735404657885523|  59.9173511982586|\n",
      "|RV162 S1D1 m0 KD1...|2020-07-03 03:26:00|         50|God sikt, opphold|  Tørr, bar veg|             Dagslys|         Ja|      null|Vanlig veg/gate|          Ukjent|10.755689174919725| 59.89888551229434|\n",
      "|    RV162 S1D1 m4383|2020-07-01 06:31:00|         50|God sikt, opphold|  Tørr, bar veg|             Dagslys|         Ja|         8|Vanlig veg/gate|   Kollektivfelt|10.730999349370787| 59.91407431454162|\n",
      "|    RV162 S1D1 m1329|2020-06-06 01:12:00|         50|God sikt, opphold|   Våt, bar veg| Tussmørke, skumring|     Ukjent|      null|Vanlig veg/gate|Vanlig kjørefelt|10.759805464340214|59.903672748268356|\n",
      "|    RV162 S1D1 m3443|2020-06-25 12:47:00|         50|God sikt, opphold|  Tørr, bar veg|Mørkt med vegbely...|         Ja|      19,9|Vanlig veg/gate|Vanlig kjørefelt|10.741203697101172|  59.9163137567185|\n",
      "|RV162 S1D1 m2312 ...|2021-08-21 22:32:00|         50|God sikt, opphold|  Tørr, bar veg|Mørkt med vegbely...|         Ja|      null|Vanlig veg/gate|          Ukjent|10.758185781957152|   59.912150910701|\n",
      "|     RV162 S1D1 m938|2021-04-09 09:44:00|         50|God sikt, opphold|  Tørr, bar veg|             Dagslys|         Ja|      null|Vanlig veg/gate|          Ukjent|10.762073618231282| 59.90684081255984|\n",
      "|     RV162 S1D1 m974|2021-11-02 05:25:00|         50|           Ukjent|         Ukjent|              Ukjent|         Ja|      null|Vanlig veg/gate|          Ukjent| 10.76181185098513| 59.90669143912908|\n",
      "|    RV162 S1D1 m4875|2021-03-12 10:21:00|         50|God sikt, opphold|  Tørr, bar veg|             Dagslys|         Ja|      10,9|Vanlig veg/gate|Vanlig kjørefelt|  10.7265728758466| 59.91193132884702|\n",
      "|    RV162 S1D1 m2324|2021-12-11 15:20:00|         50|God sikt, opphold|   Våt, bar veg|Mørkt med vegbely...|         Ja|        14|Vanlig veg/gate|          Ukjent| 10.75699791565653| 59.91163787255267|\n",
      "|     RV162 S1D1 m983|2022-04-28 18:06:00|         50|God sikt, opphold|  Tørr, bar veg|             Dagslys|         Ja|      null|Vanlig veg/gate|Vanlig kjørefelt|10.761762766312527| 59.90661554253446|\n",
      "|    RV162 S1D1 m5233|2022-08-05 10:26:00|         50|God sikt, opphold|  Tørr, bar veg|             Dagslys|         Ja|      14,5|Vanlig veg/gate|          Ukjent|10.721084998414751|59.910880521074276|\n",
      "|    RV162 S1D1 m1364|2022-06-29 17:37:00|         50|God sikt, opphold|  Tørr, bar veg|             Dagslys|         Ja|      null|       Motorveg|      Flettefelt|10.759646840245452|  59.9033624515127|\n",
      "|RV162 S1D1 m2778 ...|2022-06-22 12:49:00|         50|God sikt, opphold|  Tørr, bar veg|             Dagslys|         Ja|        10|Vanlig veg/gate|          Ukjent|10.752553318502128|59.914451065156875|\n",
      "|RV162 S1D1 m0 KD1...|2022-07-10 21:32:00|         50|God sikt, opphold|  Tørr, bar veg|Mørkt med vegbely...|         Ja|      null|Vanlig veg/gate|          Ukjent|10.755736789150362|  59.8989293089773|\n",
      "|    RV162 S1D1 m2198|2022-03-13 03:54:00|         50|God sikt, opphold|  Tørr, bar veg|Mørkt med vegbely...|         Ja|      null|Vanlig veg/gate|Vanlig kjørefelt|10.757898010960123| 59.91096267701997|\n",
      "+--------------------+-------------------+-----------+-----------------+---------------+--------------------+-----------+----------+---------------+----------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read input data and create dataframes\n",
    "df_accidents = spark.read.option(\"header\", True).csv(\"./Datasets/accidents.csv\", inferSchema=True )\n",
    "df_accidents = df_accidents.withColumn(\"timestamp\", to_utc_timestamp(col(\"Timestamp\"),\"Europe/Oslo\"))\n",
    "\n",
    "# Rename columns\n",
    "name_mapping = {\n",
    "    \"RoadReference\": \"road_reference\",\n",
    "    \"timestamp\": \"timestamp\",\n",
    "    \"SpeedLimit(KMH)\": \"speed_limit\",\n",
    "    \"Weather\": \"weather\",\n",
    "    \"RoadConditions\": \"road_conditions\",\n",
    "    \"LightingConditions\": \"lighting_conditions\",\n",
    "    \"RoadLights\": \"road_lights\",\n",
    "    \"RoadWidth(M)\": \"road_width\",\n",
    "    \"RoadType\": \"road_type\",\n",
    "    \"LaneType\": \"lane_type\",\n",
    "    \"Lon\": \"lon\",\n",
    "    \"Lat\": \"lat\"\n",
    "}\n",
    "\n",
    "# Use the select operation with alias to rename multiple columns\n",
    "df_accidents = df_accidents.select([df_accidents[column].alias(new_name) for column, new_name in name_mapping.items()])\n",
    "df_accidents.show(30) # Sanity check\n",
    "\n",
    "# Write to mongodb\n",
    "df_accidents.write.format(\"mongodb\").mode(\"overwrite\").option(\"database\", \"CS4010\").option(\"collection\", \"accidents\").save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f4fe5c-4161-44c6-a80b-60a1d4abce4b",
   "metadata": {},
   "source": [
    "# Transform, join and insert traffic data (volume & speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3bc03aa7-88d4-4259-b71d-3aaf0d8c8e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+--------+------+--------------+----------------+\n",
      "|          timestamp|       trpid|coverage|volume|avereage_speed|85fractile_speed|\n",
      "+-------------------+------------+--------+------+--------------+----------------+\n",
      "|2019-12-31 23:00:00|29403V625517|   100.0|   575|          57.8|            65.2|\n",
      "|2020-01-01 00:00:00|29403V625517|   100.0|   618|          57.7|            66.4|\n",
      "|2020-01-01 01:00:00|29403V625517|   100.0|   650|          56.7|            65.6|\n",
      "|2020-01-01 02:00:00|29403V625517|   100.0|   527|          59.6|            68.4|\n",
      "|2020-01-01 03:00:00|29403V625517|   100.0|   555|          60.8|            69.2|\n",
      "+-------------------+------------+--------+------+--------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------------------+------------+--------+------+--------------+----------------+\n",
      "|          timestamp|       trpid|coverage|volume|avereage_speed|85fractile_speed|\n",
      "+-------------------+------------+--------+------+--------------+----------------+\n",
      "|2019-12-31 23:00:00|64557V625518|   100.0|   889|          35.2|            42.2|\n",
      "|2020-01-01 00:00:00|64557V625518|   100.0|   678|          23.0|            34.3|\n",
      "|2020-01-01 01:00:00|64557V625518|   100.0|   552|          33.2|            41.9|\n",
      "|2020-01-01 02:00:00|64557V625518|   100.0|   349|          36.3|            45.6|\n",
      "|2020-01-01 03:00:00|64557V625518|   100.0|   310|          38.0|            47.5|\n",
      "+-------------------+------------+--------+------+--------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------------------+-------------+--------+------+--------------+----------------+\n",
      "|          timestamp|        trpid|coverage|volume|avereage_speed|85fractile_speed|\n",
      "+-------------------+-------------+--------+------+--------------+----------------+\n",
      "|2019-12-31 23:00:00|73840V2041694|   100.0|   549|          54.9|            62.6|\n",
      "|2020-01-01 00:00:00|73840V2041694|   100.0|   635|          54.9|            61.8|\n",
      "|2020-01-01 01:00:00|73840V2041694|   100.0|   667|          54.8|            62.5|\n",
      "|2020-01-01 02:00:00|73840V2041694|   100.0|   526|          57.0|            65.0|\n",
      "|2020-01-01 03:00:00|73840V2041694|   100.0|   543|          59.0|            66.0|\n",
      "+-------------------+-------------+--------+------+--------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------------------+-------------+--------+------+--------------+----------------+\n",
      "|          timestamp|        trpid|coverage|volume|avereage_speed|85fractile_speed|\n",
      "+-------------------+-------------+--------+------+--------------+----------------+\n",
      "|2019-12-31 23:00:00|71241V2460301|   100.0|   519|          49.9|            58.4|\n",
      "|2020-01-01 00:00:00|71241V2460301|   100.0|   417|          48.7|            57.9|\n",
      "|2020-01-01 01:00:00|71241V2460301|   100.0|   380|          51.3|            61.4|\n",
      "|2020-01-01 02:00:00|71241V2460301|   100.0|   350|          52.4|            62.8|\n",
      "|2020-01-01 03:00:00|71241V2460301|   100.0|   351|          57.3|            70.2|\n",
      "+-------------------+-------------+--------+------+--------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------------------+-------------+--------+------+--------------+----------------+\n",
      "|          timestamp|        trpid|coverage|volume|avereage_speed|85fractile_speed|\n",
      "+-------------------+-------------+--------+------+--------------+----------------+\n",
      "|2019-12-31 23:00:00|29852V2460300|   100.0|   351|          56.5|            69.4|\n",
      "|2020-01-01 00:00:00|29852V2460300|   100.0|   585|          55.5|            65.4|\n",
      "|2020-01-01 01:00:00|29852V2460300|   100.0|   573|          55.4|            64.4|\n",
      "|2020-01-01 02:00:00|29852V2460300|   100.0|   423|          57.3|            65.5|\n",
      "|2020-01-01 03:00:00|29852V2460300|   100.0|   450|          59.9|            69.4|\n",
      "+-------------------+-------------+--------+------+--------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to load, transform and save traffic volume and speed data to MongoDB\n",
    "def transformAndLoadVolumeSpeedToMongo(file_volume, file_speed):\n",
    "    # Setup\n",
    "    db_name = \"CS4010\"\n",
    "    collection_name = \"traffic_data\"\n",
    "    timezone = \"Europe/Oslo\"\n",
    "    \n",
    "    # Importing datasets and creating dataframes\n",
    "    df_volume = spark.read.option(\"header\", True).csv(f'./Datasets/{file_volume}.csv', inferSchema=True )\n",
    "    df_speed = spark.read.option(\"header\", True).csv(f'./Datasets/{file_speed}.csv', inferSchema=True )\n",
    "    \n",
    "    # Timestamp transformation\n",
    "    df_volume = df_volume.withColumn(\"timestamp\", to_utc_timestamp(col(\"toTime\"),timezone))\n",
    "    \n",
    "    # Combine time and date into a common timestamp\n",
    "    df_speed = df_speed.withColumn(\"Til tidspunkt\", date_format(col(\"Til tidspunkt\"), \"HH:mm:ss\"))\n",
    "    df_speed = df_speed.withColumn(\"Timestamp\", concat_ws(' ', col(\"Dato\"), col(\"Til tidspunkt\")).alias(\"TIMESTAMP\"))\n",
    "    df_speed = df_speed.withColumn(\"timestamp\", to_utc_timestamp(col(\"Timestamp\"),timezone))\n",
    "    \n",
    "    # Rename columns\n",
    "    volume_name_mapping = {\n",
    "        \"trpid\": \"trpid\",\n",
    "        \"timestamp\": \"timestamp\",\n",
    "        \"coverage\": \"coverage\",\n",
    "        \"volume\": \"volume\"\n",
    "    }\n",
    "    \n",
    "    speed_name_mapping = {\n",
    "        \"timestamp\": \"timestamp\",\n",
    "        \"Gjennomsnittshastighet\":\"average_speed\",\n",
    "        \"85-fraktil\": \"85fractile_speed\"\n",
    "    }\n",
    "    \n",
    "    # Use the select operation with alias to rename multiple columns\n",
    "    df_volume = df_volume.select([df_volume[column].alias(new_name) for column, new_name in volume_name_mapping.items()])\n",
    "    df_speed = df_speed.select([df_speed[column].alias(new_name) for column, new_name in speed_name_mapping.items()]) \n",
    "    \n",
    "    # Join dataframes (on time)\n",
    "    df_joined = df_volume.join(df_speed, [\"timestamp\"])\n",
    "    df_joined.orderBy(col(\"timestamp\").asc()).show(5) # Sanity check\n",
    "    \n",
    "    # Write to mongodb\n",
    "    df_joined.write.format(\"mongodb\").mode(\"append\").option(\"database\", db_name).option(\"collection\", collection_name).save()\n",
    "\n",
    "# Loop through all the traffic volume and speed data files, one pair of CSVs per trp\n",
    "document_arr = [[\"29403V625517\", \"VATERLANDTUNNELEN\"], [\"64557V625518\", \"MUNKEDAMSVEIEN\"], [\"73840V2041694\", \"STRE_TANGENT\"], [\"71241V2460301\", \"KONG_HAKON_5.S_GT_NORDGAENDE\"], [\"29852V2460300\", \"KONG_HAKON_5.S_GT_SYDGAENDE\"]]\n",
    "for trp in document_arr:\n",
    "    transformAndLoadVolumeSpeedToMongo(trp[0], trp[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7332b92-7204-4d3a-9760-02f1bbb5b94c",
   "metadata": {},
   "source": [
    "# Transform and insert metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "edeae00b-7fe6-42fe-b213-112b3f11b1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------+-----------------+-------+---------+-----------+\n",
      "|       trpid|  road_reference|             name|    lon|      lat|speed_limit|\n",
      "+------------+----------------+-----------------+-------+---------+-----------+\n",
      "|29403V625517|RV162 S1D1 m2975|VATERLANDTUNNELEN|10.7493|59.916004|         50|\n",
      "+------------+----------------+-----------------+-------+---------+-----------+\n",
      "\n",
      "+------------+----------------+--------------+---------+---------+-----------+\n",
      "|       trpid|  road_reference|          name|      lon|      lat|speed_limit|\n",
      "+------------+----------------+--------------+---------+---------+-----------+\n",
      "|64557V625518|RV162 S1D1 m4949|MUNKEDAMSVEIEN|10.725753|59.911418|         50|\n",
      "+------------+----------------+--------------+---------+---------+-----------+\n",
      "\n",
      "+-------------+----------------+-------------+---------+---------+-----------+\n",
      "|        trpid|  road_reference|         name|      lon|      lat|speed_limit|\n",
      "+-------------+----------------+-------------+---------+---------+-----------+\n",
      "|73840V2041694|RV162 S1D1 m2015|ØSTRE TANGENT|10.760802|59.910064|         50|\n",
      "+-------------+----------------+-------------+---------+---------+-----------+\n",
      "\n",
      "+-------------+---------------+--------------------+---------+---------+-----------+\n",
      "|        trpid| road_reference|                name|      lon|      lat|speed_limit|\n",
      "+-------------+---------------+--------------------+---------+---------+-----------+\n",
      "|71241V2460301|RV162 S1D1 m827|KONG HÅKON 5.S GT...|10.761554|59.905905|         50|\n",
      "+-------------+---------------+--------------------+---------+---------+-----------+\n",
      "\n",
      "+-------------+----------------+--------------------+---------+---------+-----------+\n",
      "|        trpid|  road_reference|                name|      lon|      lat|speed_limit|\n",
      "+-------------+----------------+--------------------+---------+---------+-----------+\n",
      "|29852V2460300|RV162 S1D1 m1064|KONG HÅKON 5.S GT...|10.761306|59.905927|         50|\n",
      "+-------------+----------------+--------------------+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DO NOT RERUN, IT WILL APPEND DATA\n",
    "\n",
    "def transformAndLoadMetadataToMongo(file_volume, file_speed, df_speed_limit):\n",
    "    # Setup\n",
    "    db_name = \"CS4010\"\n",
    "    collection_name = \"traffic_registration_points\"\n",
    "    \n",
    "    # Importing datasets and creating dataframes\n",
    "    df_volume = spark.read.option(\"header\", True).csv(f'./Datasets/{file_volume}.csv', inferSchema=True )\n",
    "    df_speed = spark.read.option(\"header\", True).csv(f'./Datasets/{file_speed}.csv', inferSchema=True )\n",
    "\n",
    "    # Join dataframes\n",
    "    df_joined = df_volume.join(df_speed, df_volume.trpid == df_speed.Trafikkregistreringspunkt, \"inner\")\n",
    "    \n",
    "    # Select and rename columns\n",
    "    metadata_name_mapping = {\n",
    "        \"trpid\": \"trpid\",\n",
    "        \"Vegreferanse\": \"road_reference\",\n",
    "        \"Navn\": \"name\",\n",
    "        \"lon\": \"lon\",\n",
    "        \"lat\": \"lat\"\n",
    "    }\n",
    "    df_joined = df_joined.select([df_joined[column].alias(new_name) for column, new_name in metadata_name_mapping.items()]).limit(1)\n",
    "\n",
    "    # Finding speed limit for TRP and selecting columns\n",
    "    df_joined = df_joined.withColumn(\"meter\", split(\"road_reference\", \"m\")[1])\n",
    "    df_metadata = df_joined.join(df_speed_limit)\n",
    "    df_metadata = df_metadata.filter(df_metadata.meter.between(df_metadata.Meter_Fra, df_metadata.Meter_Til))\n",
    "\n",
    "    # Selecting columns and making the name column uppercase\n",
    "    df_metadata = df_metadata.select(\"trpid\", \"road_reference\", \"name\", \"lon\", \"lat\", col(\"Fartsgrense\").alias(\"speed_limit\"))\n",
    "    df_metadata = df_metadata.withColumn(\"name\", upper(\"name\"))\n",
    "    df_metadata.show(1) # Sanity Check\n",
    "    \n",
    "    # Write to MongoDB\n",
    "    df_metadata.write.format(\"mongodb\").mode(\"append\").option(\"database\", db_name).option(\"collection\", collection_name).save()\n",
    "\n",
    "# Read the speed_limits file and create a dataframe\n",
    "df_speed_limit = spark.read.option(\"header\", True).csv(\"./Datasets/speed-limits.csv\", inferSchema=True )\n",
    "\n",
    "# Loop through all the traffic volume and speed data files, one pair of CSVs per trp. Also send in the speed limit dataframe\n",
    "document_arr = [[\"29403V625517\", \"VATERLANDTUNNELEN\"], [\"64557V625518\", \"MUNKEDAMSVEIEN\"], [\"73840V2041694\", \"STRE_TANGENT\"], [\"71241V2460301\", \"KONG_HAKON_5.S_GT_NORDGAENDE\"], [\"29852V2460300\", \"KONG_HAKON_5.S_GT_SYDGAENDE\"]]\n",
    "for trp in document_arr:\n",
    "    transformAndLoadMetadataToMongo(trp[0], trp[1], df_speed_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b237320-0ebd-468c-8d30-307ba065caa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the spark context\n",
    "spark.sparkContext.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
